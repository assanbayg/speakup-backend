version: "3.8"

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports: ["11434:11434"]
    volumes: ["ollama:/root/.ollama"]
    environment:
      - OLLAMA_KEEP_ALIVE=24h

  api:
    build: ./api
    container_name: speakup-api
    depends_on: [ollama]
    restart: unless-stopped
    ports: ["8080:8080"]
    environment:
      - OLLAMA_URL=http://ollama:11434
      - LLM_MODEL=qwen2.5:3b-instruct-q4_K_M
      - WHISPER_MODEL=medium
      - WHISPER_COMPUTE=int8
      # - XTTS_VOICE=speaker_0
      - XTTS_LANG=ru
      - TTS_FORMAT=mp3
      - TORCH_DEVICE=cpu
      - PRIVACY_DISABLE_LOGS=true
      - COQUI_TOS_AGREED=1

volumes:
  ollama:
