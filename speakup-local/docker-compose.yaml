services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports: ["11434:11434"]
    volumes: ["ollama:/root/.ollama"]
    environment:
      - OLLAMA_KEEP_ALIVE=24h

  api:
    image: assanbayg/speakup-api:latest
    container_name: speakup-api
    depends_on: [ollama]
    restart: unless-stopped
    ports: ["8080:8080"]
    environment:
      - OLLAMA_URL=http://ollama:11434
      - LLM_MODEL=qwen2.5:1.5b-instruct-q4_K_M
      - WHISPER_MODEL=small
      - WHISPER_COMPUTE=int8
      - XTTS_LANG=ru
      - TTS_FORMAT=mp3
      - TORCH_DEVICE=cpu
      - PRIVACY_DISABLE_LOGS=true
      - COQUI_TOS_AGREED=1

volumes:
  ollama: